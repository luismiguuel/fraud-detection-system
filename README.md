# ðŸ›¡ï¸ DetecÃ§Ã£o de Fraudes em TransaÃ§Ãµes Financeiras

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Status](https://img.shields.io/badge/Status-Finalizado-success)

Este projeto implementa uma soluÃ§Ã£o de Machine Learning de alta performance para a detecÃ§Ã£o de fraudes em cartÃµes de crÃ©dito. O sistema utiliza uma arquitetura de **Ensemble Learning** combinando **LightGBM** e **XGBoost**, otimizados para maximizar a mÃ©trica **ROC AUC** em cenÃ¡rios de extremo desbalanceamento de classes.

---

## ðŸ“‚ Estrutura do Projeto

O projeto segue as boas prÃ¡ticas de Engenharia de Machine Learning, segregando dados, processamento e modelagem:

```text
fraud-detection/
â”‚
â”œâ”€â”€ data/                   # DiretÃ³rio para armazenamento dos dados brutos (ignorado pelo Git)
â”‚   â”œâ”€â”€ train.csv           # Dataset de treino
â”‚   â””â”€â”€ test.csv            # Dataset de teste (sem target)
â”‚
â”œâ”€â”€ models/                 # Artefatos serializados dos modelos treinados
â”‚   â”œâ”€â”€ lgbm_model.pkl      # Modelo LightGBM final
â”‚   â””â”€â”€ xgboost_model.pkl   # Modelo XGBoost final
â”‚
â”œâ”€â”€ src/                    # CÃ³digo fonte modularizado
â”‚   â”œâ”€â”€ preprocessing.py    # Pipelines de limpeza e engenharia de features
â”‚   â””â”€â”€ training.py         # LÃ³gica de treinamento, validaÃ§Ã£o cruzada e ensemble
â”‚
â”œâ”€â”€ main.py                 # Orquestrador principal da execuÃ§Ã£o
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto com versÃµes travadas
â””â”€â”€ README.md               # DocumentaÃ§Ã£o oficial
```

## ðŸš€ Guia de InstalaÃ§Ã£o e ExecuÃ§Ã£o
Siga os passos abaixo para reproduzir os resultados em seu ambiente local.

### **1. PrÃ©-requisitos**

Certifique-se de ter o Python 3.8+ instalado. Recomenda-se o uso de um ambiente virtual (venv).

### **2. InstalaÃ§Ã£o das DependÃªncias**

Clone este repositÃ³rio e instale as bibliotecas necessÃ¡rias:

```bash
pip install -r requirements.txt
```

*Nota: As versÃµes das bibliotecas foram fixadas para garantir a reprodutibilidade exata dos resultados.*

### **3. ConfiguraÃ§Ã£o dos Dados**

Devido o tamanho, os dados nÃ£o estÃ£o no repositÃ³rio.

Baixe os arquivos `train.csv` e `test.csv` da competiÃ§Ã£o no [Kaggle](https://www.kaggle.com/competitions/ligia-machine-learning/data).

Crie uma pasta chamada `data` na raiz do projeto.

Mova os arquivos `.csv` para dentro da pasta `data`.

### **4. Executando o Pipeline**

Para rodar o processo completo, execute o arquivo principal:

```bash
python main.py
```
### **O que o script farÃ¡:**

CarregarÃ¡ os dados e aplicarÃ¡ normalizaÃ§Ã£o (RobustScaler) e engenharia temporal.

TreinarÃ¡ os modelos LightGBM e XGBoost com ValidaÃ§Ã£o Cruzada Estratificada (5 Folds).

SalvarÃ¡ os modelos treinados na pasta `models`.

GerarÃ¡ o arquivo `submission.csv` na raiz do projeto.

## ðŸ“Š Performance e Resultados

A soluÃ§Ã£o foi avaliada utilizando a mÃ©trica **ROC** **AUC**.

| Ambiente | Score (AUC) |
| --- | --- |
| ValidaÃ§Ã£o local | ~0.9653
| Kaggle | 0.9846

### **Destaques da Metodologia:**

**Seed 42:** Fixada em todas as bibliotecas para garantir determinismo.

**Feature Engineering:** TransformaÃ§Ã£o da variÃ¡vel Time em "Hora do Dia" para capturar padrÃµes temporais de fraude.

**Tratamento de Desbalanceamento:** Uso de `is_unbalance=True` (LGBM) e `scale_pos_weight` (XGBoost) em vez de resampling artificial, preservando a distribuiÃ§Ã£o original dos dados.

## ðŸ§  Interpretabilidade e AnÃ¡lise CrÃ­tica (SHAP)

Utilizamos a biblioteca **SHAP (SHapley Additive exPlanations)** para abrir a "caixa-preta" dos modelos e entender os fatores de decisÃ£o. A anÃ¡lise comparativa revelou que o LightGBM e o XGBoost "olham" para os dados de formas distintas, o que justifica a alta performance do Ensemble.

### **1. LightGBM: Agressividade e Foco Estrutural**
![SHAP LGBM](reports/shap_summary_LGBM.png)

O LightGBM demonstrou um comportamento mais concentrado e agressivo:
* **DominÃ¢ncia da Feature V4:** Ã‰ a variÃ¡vel soberana no modelo, com amplitude de impacto SHAP muito alta (de -2 a +5). Valores altos em `V4` (pontos vermelhos) indicam forte probabilidade de fraude.
* **Alta NÃ£o-Linearidade:** O modelo depende drasticamente de poucas variÃ¡veis (`V4`, `V1`, `V16`) para tomar decisÃµes, ignorando quase totalmente o contexto de `Amount` (valor) e `Time`.
* **Risco:** Apresenta maior sensibilidade a outliers nessas features especÃ­ficas.

### **2. XGBoost: Estabilidade e Contexto**
![SHAP XGBoost](reports/shap_summary_XGBM.png)

O XGBoost apresentou uma distribuiÃ§Ã£o de importÃ¢ncia mais equilibrada e robusta:
* **DominÃ¢ncia da Feature V14:** Diferente do LGBM, aqui a feature `V14` Ã© o principal discriminador. Valores baixos (pontos azuis) aumentam drasticamente o risco de fraude.
* **Uso de Contexto (Amount & Time):** Ao contrÃ¡rio do LGBM, o XGBoost considerou `Amount_Scaled` e `Time_Scaled` como variÃ¡veis relevantes. Isso significa que ele consegue detectar fraudes baseadas no valor da transaÃ§Ã£o e no horÃ¡rio, nÃ£o apenas em padrÃµes matemÃ¡ticos abstratos (V's).
* **Estabilidade:** A amplitude dos valores SHAP Ã© menor (~2), sugerindo um modelo menos propenso a overfitting extremo.

### **3. LimitaÃ§Ãµes e Trade-off de NegÃ³cio**
Embora o modelo minimize Falsos Negativos (deixando passar poucas fraudes), a agressividade do LightGBM em features como `V4` pode gerar alguns **Falsos Positivos** (bloqueio de clientes legÃ­timos). Em um cenÃ¡rio real de produÃ§Ã£o, recomenda-se uma camada humana de revisÃ£o para scores limÃ­trofes (entre 0.7 e 0.9) para evitar atrito com o cliente.

### **4. ConclusÃ£o: O Poder da Complementaridade**
A anÃ¡lise SHAP explica o porquÃª a soluÃ§Ã£o atingiu **AUC 0.9846**:

> **HipÃ³tese Confirmada:** Existe uma **complementaridade estrutural**. Onde o LightGBM Ã© agressivo e focado na feature `V4`, o XGBoost traz equilÃ­brio focando em `V14` e adicionando o contexto de `Amount` e `Time`. O Ensemble combina o melhor desses dois mundos, cobrindo os "pontos cegos" individuais de cada algoritmo.

## ðŸ‘¤ Autor
Luis Miguel de Almeida Lima
* LinkedIn: [Luis Miguel Lima](https://www.linkedin.com/in/luis-miguel-lima-b10684379/)
* GitHub: [luismiguuel](https://github.com/luismiguuel)