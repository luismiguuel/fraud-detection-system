# ğŸ›¡ï¸ DetecÃ§Ã£o de Fraudes em TransaÃ§Ãµes Financeiras

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Status](https://img.shields.io/badge/Status-Finalizado-success)

Este projeto implementa uma soluÃ§Ã£o de Machine Learning de alta performance para a detecÃ§Ã£o de fraudes em cartÃµes de crÃ©dito. O sistema utiliza uma arquitetura de **Ensemble Learning** combinando **LightGBM** e **XGBoost**, otimizados para maximizar a mÃ©trica **ROC AUC** em cenÃ¡rios de extremo desbalanceamento de classes.

---

## ğŸ“‚ Estrutura do Projeto

O projeto segue as boas prÃ¡ticas de Engenharia de Machine Learning, segregando dados, processamento e modelagem:

```text
fraud-detection/
â”‚
â”œâ”€â”€ data/                   # DiretÃ³rio para armazenamento dos dados brutos (ignorado pelo Git)
â”‚   â”œâ”€â”€ train.csv           # Dataset de treino
â”‚   â””â”€â”€ test.csv            # Dataset de teste (sem target)
â”‚
â”œâ”€â”€ models/                 # Artefatos serializados dos modelos treinados
â”‚   â”œâ”€â”€ lgbm_model.pkl      # Modelo LightGBM final
â”‚   â””â”€â”€ xgboost_model.pkl   # Modelo XGBoost final
â”‚
â”œâ”€â”€ src/                    # CÃ³digo fonte modularizado
â”‚   â”œâ”€â”€ preprocessing.py    # Pipelines de limpeza e engenharia de features
â”‚   â””â”€â”€ training.py         # LÃ³gica de treinamento, validaÃ§Ã£o cruzada e ensemble
â”‚
â”œâ”€â”€ main.py                 # Orquestrador principal da execuÃ§Ã£o
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto com versÃµes travadas
â””â”€â”€ README.md               # DocumentaÃ§Ã£o oficial
```

## ğŸš€ Guia de InstalaÃ§Ã£o e ExecuÃ§Ã£o
Siga os passos abaixo para reproduzir os resultados em seu ambiente local.

**1. PrÃ©-requisitos**

Certifique-se de ter o Python 3.8+ instalado. Recomenda-se o uso de um ambiente virtual (venv).

**2. InstalaÃ§Ã£o das DependÃªncias**

Clone este repositÃ³rio e instale as bibliotecas necessÃ¡rias:

```bash
pip install -r requirements.txt
```

*Nota: As versÃµes das bibliotecas foram fixadas para garantir a reprodutibilidade exata dos resultados.*

**3. ConfiguraÃ§Ã£o dos Dados**

Devido o tamanho, os dados nÃ£o estÃ£o no repositÃ³rio.

Baixe os arquivos `train.csv` e `test.csv` da competiÃ§Ã£o no [Kaggle](https://www.kaggle.com/competitions/ligia-machine-learning/data).

Crie uma pasta chamada `data` na raiz do projeto.

Mova os arquivos `.csv` para dentro da pasta `data`.

**4. Executando o Pipeline**

Para rodar o processo completo, execute o arquivo principal:

```bash
python main.py
```
**O que o script farÃ¡:**

CarregarÃ¡ os dados e aplicarÃ¡ normalizaÃ§Ã£o (RobustScaler) e engenharia temporal.

TreinarÃ¡ os modelos LightGBM e XGBoost com ValidaÃ§Ã£o Cruzada Estratificada (5 Folds).

SalvarÃ¡ os modelos treinados na pasta `models`.

GerarÃ¡ o arquivo `submission.csv` na raiz do projeto.

## ğŸ“Š Performance e Resultados

A soluÃ§Ã£o foi avaliada utilizando a mÃ©trica **ROC** **AUC**.

| Ambiente | Score (AUC) |
| --- | --- |
| ValidaÃ§Ã£o local | ~0.9653
| Kaggle | 0.9846

**Destaques da Metodologia:**

**Seed 42:** Fixada em todas as bibliotecas para garantir determinismo.

**Feature Engineering:** TransformaÃ§Ã£o da variÃ¡vel Time em "Hora do Dia" para capturar padrÃµes temporais de fraude.

**Tratamento de Desbalanceamento:** Uso de `is_unbalance=True` (LGBM) e `scale_pos_weight` (XGBoost) em vez de resampling artificial, preservando a distribuiÃ§Ã£o original dos dados.

## ğŸ‘¤ Autor
Luis Miguel de Almeida Lima
* LinkedIn: [Luis Miguel Lima](https://www.linkedin.com/in/luis-miguel-lima-b10684379/)
* GitHub: [luismiguuel](https://github.com/luismiguuel)